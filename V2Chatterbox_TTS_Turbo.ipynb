{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/britt21/ChattaBOX/blob/main/V2Chatterbox_TTS_Turbo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlAlQeNZU6k4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsDDevyVuCOz",
        "outputId": "2887ac89-2c4a-4862-dce9-72683850390f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin/micromamba\n",
            "\n",
            "\n",
            "Transaction\n",
            "\n",
            "  Prefix: /root/.local/share/mamba/envs/cb311\n",
            "\n",
            "  Updating specs:\n",
            "\n",
            "   - python=3.11\n",
            "   - pip\n",
            "\n",
            "\n",
            "  Package              Version  Build                 Channel          Size\n",
            "─────────────────────────────────────────────────────────────────────────────\n",
            "  Install:\n",
            "─────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "  + _libgcc_mutex          0.1  conda_forge           conda-forge       3kB\n",
            "  + _openmp_mutex          4.5  2_gnu                 conda-forge      24kB\n",
            "  + bzip2                1.0.8  hda65f42_8            conda-forge     260kB\n",
            "  + ca-certificates   2026.1.4  hbd8a1cb_0            conda-forge     147kB\n",
            "  + icu                   78.2  h33c6efd_0            conda-forge      13MB\n",
            "  + ld_impl_linux-64      2.45  default_hbd61a6d_105  conda-forge     731kB\n",
            "  + libexpat             2.7.3  hecca717_0            conda-forge      77kB\n",
            "  + libffi               3.5.2  h9ec8514_0            conda-forge      58kB\n",
            "  + libgcc              15.2.0  he0feb66_16           conda-forge       1MB\n",
            "  + libgcc-ng           15.2.0  h69a702a_16           conda-forge      27kB\n",
            "  + libgomp             15.2.0  he0feb66_16           conda-forge     603kB\n",
            "  + liblzma              5.8.1  hb9d3cd8_2            conda-forge     113kB\n",
            "  + libnsl               2.0.1  hb9d3cd8_1            conda-forge      34kB\n",
            "  + libsqlite           3.51.2  hf4e2dac_0            conda-forge     943kB\n",
            "  + libstdcxx           15.2.0  h934c35e_16           conda-forge       6MB\n",
            "  + libuuid             2.41.3  h5347b49_0            conda-forge      40kB\n",
            "  + libxcrypt           4.4.36  hd590300_1            conda-forge     100kB\n",
            "  + libzlib              1.3.1  hb9d3cd8_2            conda-forge      61kB\n",
            "  + ncurses                6.5  h2d0b736_3            conda-forge     892kB\n",
            "  + openssl              3.6.0  h26f9b46_0            conda-forge       3MB\n",
            "  + pip                   25.3  pyh8b19718_0          conda-forge       1MB\n",
            "  + python             3.11.14  hd63d673_2_cpython    conda-forge      31MB\n",
            "  + readline               8.3  h853b02a_0            conda-forge     345kB\n",
            "  + setuptools          80.9.0  pyhff2d567_0          conda-forge     749kB\n",
            "  + tk                  8.6.13  noxft_ha0e22de_103    conda-forge       3MB\n",
            "  + tzdata               2025c  hc9c84f9_1            conda-forge     119kB\n",
            "  + wheel               0.45.1  pyhd8ed1ab_1          conda-forge      63kB\n",
            "  + zstd                 1.5.7  hb78ec9c_6            conda-forge     601kB\n",
            "\n",
            "  Summary:\n",
            "\n",
            "  Install: 28 packages\n",
            "\n",
            "  Total download: 64MB\n",
            "\n",
            "─────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "\n",
            "\n",
            "Transaction starting\n",
            "Linking tzdata-2025c-hc9c84f9_1\n",
            "Linking ca-certificates-2026.1.4-hbd8a1cb_0\n",
            "Linking libgomp-15.2.0-he0feb66_16\n",
            "Linking _libgcc_mutex-0.1-conda_forge\n",
            "Linking _openmp_mutex-4.5-2_gnu\n",
            "Linking libgcc-15.2.0-he0feb66_16\n",
            "Linking libstdcxx-15.2.0-h934c35e_16\n",
            "Linking openssl-3.6.0-h26f9b46_0\n",
            "Linking ncurses-6.5-h2d0b736_3\n",
            "Linking libzlib-1.3.1-hb9d3cd8_2\n",
            "Linking libgcc-ng-15.2.0-h69a702a_16\n",
            "Linking libuuid-2.41.3-h5347b49_0\n",
            "Linking libnsl-2.0.1-hb9d3cd8_1\n",
            "Linking liblzma-5.8.1-hb9d3cd8_2\n",
            "Linking libexpat-2.7.3-hecca717_0\n",
            "Linking bzip2-1.0.8-hda65f42_8\n",
            "Linking libffi-3.5.2-h9ec8514_0\n",
            "Linking icu-78.2-h33c6efd_0\n",
            "Linking readline-8.3-h853b02a_0\n",
            "Linking zstd-1.5.7-hb78ec9c_6\n",
            "Linking tk-8.6.13-noxft_ha0e22de_103\n",
            "Linking libxcrypt-4.4.36-hd590300_1\n",
            "Linking libsqlite-3.51.2-hf4e2dac_0\n",
            "Linking ld_impl_linux-64-2.45-default_hbd61a6d_105\n",
            "Linking python-3.11.14-hd63d673_2_cpython\n",
            "Linking pip-25.3-pyh8b19718_0\n",
            "Linking setuptools-80.9.0-pyhff2d567_0\n",
            "Linking wheel-0.45.1-pyhd8ed1ab_1\n",
            "\n",
            "Transaction finished\n",
            "\n",
            "\n",
            "To activate this environment, use:\n",
            "\n",
            "    micromamba activate cb311\n",
            "\n",
            "Or to execute a single command in this environment, use:\n",
            "\n",
            "    micromamba run -n cb311 mycommand\n",
            "\n",
            "✅ micromamba ready at /content/bin/micromamba\n",
            "✅ env created: cb311\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "cd /content\n",
        "\n",
        "# Download micromamba into /content/bin/micromamba\n",
        "curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba\n",
        "\n",
        "# Create a clean env (isolated from Colab’s global packages)\n",
        "./bin/micromamba create -y -n cb311 -c conda-forge python=3.11 pip\n",
        "\n",
        "echo \"✅ micromamba ready at /content/bin/micromamba\"\n",
        "echo \"✅ env created: cb311\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2alxTXqZuGhl"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "cd /content\n",
        "MICROMAMBA=\"/content/bin/micromamba\"\n",
        "\n",
        "ts() { date +\"[%Y-%m-%d %H:%M:%S]\"; }\n",
        "\n",
        "echo \"$(ts) Sanity check micromamba:\"\n",
        "ls -lah \"$MICROMAMBA\"\n",
        "\n",
        "echo \"$(ts) Upgrading pip tooling inside cb311...\"\n",
        "\"$MICROMAMBA\" run -n cb311 python -m pip install -U pip setuptools wheel --progress-bar on\n",
        "\n",
        "echo \"$(ts) Installing PyTorch 2.5.1 (CUDA 12.1)... (this can take a while)\"\n",
        "\"$MICROMAMBA\" run -n cb311 pip install \\\n",
        "  --progress-bar on \\\n",
        "  torch==2.5.1+cu121 torchaudio==2.5.1+cu121 torchvision==0.20.1+cu121 \\\n",
        "  --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "echo \"$(ts) Installing ONNX (wheel)...\"\n",
        "\"$MICROMAMBA\" run -n cb311 pip install --progress-bar on onnx==1.16.0\n",
        "\n",
        "echo \"$(ts) Installing Chatterbox package (from GitHub, no-cache, upgrade)...\"\n",
        "\"$MICROMAMBA\" run -n cb311 pip uninstall -y chatterbox-tts chatterbox || true\n",
        "\"$MICROMAMBA\" run -n cb311 pip install \\\n",
        "  --no-cache-dir --upgrade \\\n",
        "  --progress-bar on \\\n",
        "  \"chatterbox-tts @ git+https://github.com/devnen/chatterbox-v2.git@master\"\n",
        "\n",
        "echo \"$(ts) ✅ Installation complete!\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_xf1scGKFNe"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "/content/bin/micromamba run -n cb311 python - <<'PY'\n",
        "import inspect, torch\n",
        "import chatterbox.tts_turbo as t\n",
        "\n",
        "print(\"✅ torch:\", torch.__version__)\n",
        "print(\"✅ cuda available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"✅ gpu:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "print(\"✅ chatterbox.tts_turbo path:\", t.__file__)\n",
        "\n",
        "src = inspect.getsource(t.ChatterboxTurboTTS.from_pretrained)\n",
        "print(\"\\n--- from_pretrained() (first ~80 lines) ---\")\n",
        "print(\"\\n\".join(src.splitlines()[:80]))\n",
        "\n",
        "# Heuristic check for the common buggy pattern that forces token=True semantics\n",
        "markers = [\" or True\", \"token=True\", \"token = True\", \"use_auth_token=True\"]\n",
        "hits = [m for m in markers if m in src]\n",
        "print(\"\\nHeuristic auth-forcing markers found:\", hits)\n",
        "\n",
        "if hits:\n",
        "    raise SystemExit(\n",
        "        \"\\n❌ This install still appears to force HF auth.\\n\"\n",
        "        \"Re-run Cell 2 (it already uses --no-cache-dir --upgrade).\\n\"\n",
        "    )\n",
        "\n",
        "print(\"\\n✅ Looks good: Turbo should download without requiring user tokens.\")\n",
        "PY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UPqwHa_lKa2B"
      },
      "outputs": [],
      "source": [
        "# @title 4. Install Server + Run With Full Live Logs (foreground)\n",
        "import os, time, subprocess, socket, requests\n",
        "from pathlib import Path\n",
        "\n",
        "PORT = 8004\n",
        "REPO_DIR = \"/content/Chatterbox-TTS-Server\"\n",
        "LOG_STDOUT = \"/content/chatterbox_server_stdout.log\"\n",
        "\n",
        "def sh(cmd, check=False):\n",
        "    return subprocess.run([\"bash\", \"-lc\", cmd], check=check)\n",
        "\n",
        "def port_open(host=\"127.0.0.1\", port=PORT, timeout=0.25):\n",
        "    try:\n",
        "        with socket.create_connection((host, port), timeout=timeout):\n",
        "            return True\n",
        "    except OSError:\n",
        "        return False\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "# Fresh clone\n",
        "sh(\"rm -rf /content/Chatterbox-TTS-Server\", check=False)\n",
        "sh(\"git clone https://github.com/devnen/Chatterbox-TTS-Server.git\", check=True)\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "print(\"=== Quick system checks ===\")\n",
        "sh(\"nvidia-smi || true\", check=False)\n",
        "\n",
        "print(\"\\n=== Installing server requirements (prefer repo pins if present) ===\")\n",
        "if Path(\"requirements-nvidia.txt\").exists():\n",
        "    sh(\"/content/bin/micromamba run -n cb311 pip install -U pip setuptools wheel\", check=False)\n",
        "    sh(\"/content/bin/micromamba run -n cb311 pip install -r requirements-nvidia.txt\", check=False)\n",
        "else:\n",
        "    sh(\n",
        "        \"/content/bin/micromamba run -n cb311 pip install -U pip setuptools wheel && \"\n",
        "        \"/content/bin/micromamba run -n cb311 pip install \"\n",
        "        \"fastapi 'uvicorn[standard]' pyyaml soundfile librosa safetensors \"\n",
        "        \"python-multipart requests jinja2 watchdog aiofiles unidecode inflect tqdm \"\n",
        "        \"pydub audiotsm praat-parselmouth\",\n",
        "        check=False\n",
        "    )\n",
        "\n",
        "print(\"\\n=== Removing old stdout log ===\")\n",
        "Path(LOG_STDOUT).unlink(missing_ok=True)\n",
        "\n",
        "print(\"\\n=== Starting server with LIVE logs ===\")\n",
        "print(\"Log file:\", LOG_STDOUT)\n",
        "print(\"To stop the server, run Cell 5.\\n\")\n",
        "\n",
        "env = os.environ.copy()\n",
        "env[\"PYTHONUNBUFFERED\"] = \"1\"\n",
        "\n",
        "# Put HF cache somewhere inspectable/persistent for this runtime\n",
        "env[\"HF_HOME\"] = \"/content/hf_home\"\n",
        "env[\"TRANSFORMERS_CACHE\"] = \"/content/hf_home/transformers\"\n",
        "env[\"HF_HUB_CACHE\"] = \"/content/hf_home/hub\"\n",
        "Path(env[\"HF_HOME\"]).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "proc = subprocess.Popen(\n",
        "    [\"/content/bin/micromamba\", \"run\", \"-n\", \"cb311\", \"python\", \"-u\", \"server.py\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1,\n",
        "    env=env,\n",
        ")\n",
        "\n",
        "with open(LOG_STDOUT, \"w\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
        "    shown_link = False\n",
        "    while True:\n",
        "        line = proc.stdout.readline()\n",
        "        if line:\n",
        "            print(line, end=\"\")\n",
        "            f.write(line)\n",
        "            f.flush()\n",
        "\n",
        "        if (not shown_link) and port_open():\n",
        "            shown_link = True\n",
        "            print(\"\\n=== Server port is reachable ===\")\n",
        "            print(\"Click the Colab proxy link below to open the Web UI.\")\n",
        "            from google.colab.output import serve_kernel_port_as_window\n",
        "            serve_kernel_port_as_window(PORT)\n",
        "\n",
        "            # Verify model load status via server endpoint\n",
        "            try:\n",
        "                mi = requests.get(f\"http://127.0.0.1:{PORT}/api/model-info\", timeout=2).json()\n",
        "                print(\"\\n/api/model-info:\", mi)\n",
        "            except Exception as e:\n",
        "                print(\"\\n/api/model-info query failed:\", repr(e))\n",
        "\n",
        "        if proc.poll() is not None:\n",
        "            print(\"\\n=== Server process exited with code\", proc.returncode, \"===\")\n",
        "            break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}